{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
                "from PIL import Image\n",
                "from matplotlib import pyplot  as plt\n",
                "import numpy as np\n",
                "import math"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "mtcnn = MTCNN(image_size=160,\n",
                "              margin=0,\n",
                "              min_face_size=20,\n",
                "              thresholds=[0.6, 0.7, 0.7], # MTCNN thresholds\n",
                "              factor=0.709,\n",
                "              post_process=True,\n",
                "              device='cpu' # If you don't have GPU\n",
                "        )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# Landmarks: [Left Eye], [Right eye], [nose], [left mouth], [right mouth]\n",
                "def npAngle(a, b, c):\n",
                "    ba = a - b\n",
                "    bc = c - b \n",
                "    \n",
                "    cosine_angle = np.dot(ba, bc)/(np.linalg.norm(ba)*np.linalg.norm(bc))\n",
                "    angle = np.arccos(cosine_angle)\n",
                "    \n",
                "    return np.degrees(angle)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def visualize(image, landmarks, angle_R, angle_L, pred):\n",
                "    fig , ax = plt.subplots(1, 1, figsize= (10,10))\n",
                "    ax.set_title(\"Output Image\")\n",
                "    ax.imshow(image)\n",
                "    point1 = [landmarks[0][0][0], landmarks[0][1][0]]\n",
                "    point2 = [landmarks[0][0][1], landmarks[0][1][1]]\n",
                "\n",
                "    point3 = [landmarks[0][2][0], landmarks[0][0][0]]\n",
                "    point4 = [landmarks[0][2][1], landmarks[0][0][1]]\n",
                "    \n",
                "    point5 = [landmarks[0][2][0], landmarks[0][1][0]]\n",
                "    point6 = [landmarks[0][2][1], landmarks[0][1][1]]\n",
                "    for land in landmarks[0]:\n",
                "        ax.scatter(land[0], land[1])\n",
                "    plt.plot(point1, point2, 'y', linewidth=3)\n",
                "    plt.plot(point3, point4, 'y', linewidth=3)\n",
                "    plt.plot(point5, point6, 'y', linewidth=3)\n",
                "    plt.text(10, 10, f\"Detect: {pred} \\n Angles: {math.floor(angle_L)}, {math.floor(angle_R)}\", \n",
                "            size=20, ha=\"center\", va=\"center\", bbox={'facecolor': 'white', 'alpha': 0.5, 'pad': 10})"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "def predFacePose(imgaePath):\n",
                "\n",
                "    im = Image.open(imgaePath) # Reading the image\n",
                "    \n",
                "    if im.mode != \"RGB\": # Convert the image if it has more than 3 channels, because MTCNN will refuse anything more than 3 channels.\n",
                "        im = im.convert('RGB')\n",
                "    \n",
                "    bbox, prob, landmarks = mtcnn.detect(im, landmarks=True) # The detection part producing bounding box, probability of the detected face, and the facial landmarks\n",
                "    print(f\"bbox: {prob}\")\n",
                "    if bbox is not None: # To check if we detect a face in the image\n",
                "        if prob > 0.9: # To check if the detected face has probability more than 90%, to avoid \n",
                "        \n",
                "            angR = npAngle(landmarks[0][0], landmarks[0][1], landmarks[0][2]) # Calculate the right eye angle\n",
                "            angL = npAngle(landmarks[0][1], landmarks[0][0], landmarks[0][2])# Calculate the left eye angle\n",
                "\n",
                "            if ((int(angR) in range(35, 57)) and (int(angL) in range(35, 58))):\n",
                "                predLabel='Frontal'\n",
                "                visualize(im, landmarks, angR, angL, predLabel)\n",
                "            else: \n",
                "                if angR < angL:\n",
                "                    predLabel='Left Profile'\n",
                "                else:\n",
                "                    predLabel='Right Profile'\n",
                "                visualize(im, landmarks, angR, angL, predLabel)\n",
                "        else:\n",
                "            print('The detected face is Less then the detection threshold')\n",
                "    else:\n",
                "        print('No face detected in the image')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Note: It will only be valid for images with one face in it \n",
                "predFacePose(\"Image/Path\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}